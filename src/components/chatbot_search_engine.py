import time
import streamlit as st
from langchain_community.retrievers import TavilySearchAPIRetriever
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

from .chatbot_setup import load_prompt
from .chatbot_db_manager import load_chroma_db, format_docs

@st.cache_data(show_spinner=False)
def web_search(query):
    """Perform web search using Tavily API"""
    retriever = TavilySearchAPIRetriever(
        k=3, 
        search_depth="advanced", 
        include_domains=["news"], 
        verbose=False
    )
    return retriever.invoke(query)

def web_rag_chain(query, llm):
    """Create RAG chain for web search results"""
    # Load web RAG prompt
    web_prompt_template = ChatPromptTemplate.from_template(load_prompt("web_rag_prompt.txt"))
    
    # Perform search and format results
    search_results = web_search(query)
    formatted_results = format_docs(search_results)
    
    # Create final prompt and invoke LLM
    final_prompt = web_prompt_template.format(context=formatted_results, question=query)
    
    time.sleep(1)
    return llm.invoke(final_prompt)

def create_pdf_rag_chain(llm):
    """Create RAG chain for PDF documents"""
    db = load_chroma_db()
    retriever = db.as_retriever()
    
    # Load PDF RAG prompt
    pdf_prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template=load_prompt("pdf_rag_prompt.txt")
    )
    
    # Create and return the RAG chain
    return (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | pdf_prompt_template
        | llm
        | StrOutputParser()
    )

def process_searches(llm):
    """Process search requests based on loading state"""
    if st.session_state["loading"]:
        with st.spinner("ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.ğŸ™"):
            # Get conversation summary
            summary = st.session_state["chatbot"].summarize_conversation()
            
            # Check if summary is empty
            if summary.strip() == "ì§ˆë¬¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤." or summary.strip() == "ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.":
                st.warning("âš ï¸ ì•„ë¬´ëŸ° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € AIì™€ ëŒ€í™”ë¥¼ ì§„í–‰í•´ ì£¼ì„¸ìš”.")
                st.session_state["loading"] = False
            else:
                print(summary)
                
                # Handle case search
                if st.session_state["loading"] == "case":
                    time.sleep(1)
                    st.session_state["case_result"] = web_rag_chain(f"{summary} ê´€ë ¨ëœ í˜•ëŸ‰ì´ë‚˜ ë²Œê¸ˆ ì •ë³´", llm)
                
                # Handle law search
                if st.session_state["loading"] == "law":
                    time.sleep(1)
                    pdf_rag_chain = create_pdf_rag_chain(llm)
                    st.session_state["law_result"] = pdf_rag_chain.invoke(f"{summary} ê´€ë ¨ëœ ë²•ë¥  ì •ë³´")
                
                # Reset loading state
                st.session_state["loading"] = False
