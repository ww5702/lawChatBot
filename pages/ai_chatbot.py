
import os
import streamlit as st
import sys
# âœ… ê°•ì œë¡œ pysqlite3ë¥¼ sqlite3ë¡œ ë“±ë¡
os.environ["SQLITE_LIBRARY_PATH"] = "/usr/lib/sqlite3"  # ì´ ì¤„ì€ ë¬´ì‹œ ê°€ëŠ¥ (ì„œë²„ ë”°ë¼ ë‹¤ë¦„)
import pysqlite3
sys.modules["sqlite3"] = pysqlite3

import sqlite3
import time

from langchain_community.retrievers import TavilySearchAPIRetriever
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain_community.vectorstores import Chroma
from chromadb.config import Settings
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.schema.output_parser import StrOutputParser
from openai import OpenAI
from langchain_openai import ChatOpenAI
import requests
from bs4 import BeautifulSoup
import fitz  # PyMuPDF
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.schema import Document
from langchain.prompts import PromptTemplate


st.set_page_config(
    page_title="ì‹¤ì‹œê°„ AI ë²•ë¥  ìƒë‹´",
    page_icon="ğŸ’¬",
    layout="centered",  # "wide"ì—ì„œ "centered"ë¡œ ë³€ê²½
    initial_sidebar_state="expanded"
)


# í˜„ì¬ íŒŒì¼(ai_chatbot.py)ì˜ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ lawChatBot ê²½ë¡œ ì¶”ê°€
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # lawChatBot ë””ë ‰í† ë¦¬ ê²½ë¡œ
sys.path.append(BASE_DIR)  # Python import ê²½ë¡œì— ì¶”ê°€

# agent ê´€ë¦¬ íŒŒì¼
from agent import Agent
# key ê°’
from config import load_keys

# í˜„ì¬ í˜ì´ì§€ ì‹ë³„
current_page = "ai_chatbot"

# ####################################################
# [ code ìˆœì„œ ]                              
# 1. openai-api key
# 2. ì±—ë´‡ í”„ë¡¬í”„íŠ¸, agent ì •ì˜
# 3. chatbotê°ì²´(streamlit) ìƒì„± ë° ê¸°ëŠ¥ êµ¬í˜„
# 4. DBêµ¬ì¶• ë° pdf_rag_chain ìƒì„±
# 5. tavilyê²€ìƒ‰í•˜ëŠ” web_rag_chain ìƒì„±
# 6. ë””ë¹„, ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
####################################################


################ 1. openai-api key #################

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
# openai_api_key, tavily_api_key = load_keys()
openai_api_key = st.secrets["OPENAI_API_KEY"]
tavily_api_key = st.secrets["TAVILY_API_KEY"]


client = OpenAI(api_key=openai_api_key)
os.environ["TAVILY_API_KEY"] = tavily_api_key

os.environ["OPENAI_API_KEY"] = openai_api_key
os.environ['USER_AGENT']='MyCustomAgent'
# ì•„ë˜ ì½”ë“œ Warning ì œê±°

# ChromaDB ë¯¸ë¦¬ ë¡œë“œí•˜ì—¬ ê²€ìƒ‰ ì†ë„ ìµœì í™”
@st.cache_resource
def load_chroma_db():
    return Chroma(
        persist_directory=os.path.join(os.path.dirname(__file__), "chroma_Web"),
        embedding_function=OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=openai_api_key),
        client_settings=Settings(chroma_db_impl="duckdb+parquet")
    )

db = load_chroma_db()
retriever = db.as_retriever()

llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0.1,
    openai_api_key=openai_api_key,
    max_tokens=256 # ìµœëŒ€ í† ê·¼ 256
)

# í”„ë¡¬í”„íŠ¸ ë¡œë“œ í•¨ìˆ˜ ì¶”ê°€
# def load_prompt(filename):
#     base_path = os.path.dirname(__file__)  # í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ë””ë ‰í† ë¦¬
#     prompt_path = os.path.join(base_path, "prompts", filename)  # ì ˆëŒ€ ê²½ë¡œë¡œ ì„¤ì •
#     with open(prompt_path, "r", encoding="utf-8") as file:
#         return file.read()
def load_prompt(filename):
    # lawChatBot ë‚´ prompts í´ë” ê²½ë¡œ ì„¤ì •
    prompt_path = os.path.join(BASE_DIR, "prompts", filename)  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
    with open(prompt_path, "r", encoding="utf-8") as file:
        return file.read()

# ì´ì „ í˜ì´ì§€ë¥¼ ê¸°ì–µí•˜ëŠ” ìƒíƒœê°€ ì—†ê±°ë‚˜, ë³€ê²½ëœ ê²½ìš° ì´ˆê¸°í™”
if "last_page" not in st.session_state or st.session_state.last_page != current_page:
    st.session_state.clear()  # ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.last_page = current_page  # í˜„ì¬ í˜ì´ì§€ë¥¼ ì €ì¥í•˜ì—¬ ë¹„êµ


st.title("ğŸ’¬ ì‹¤ì‹œê°„ AI ë²•ë¥  ìƒë‹´")
st.caption("ğŸ’¬ ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  AI ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•´ ë³´ì„¸ìš”.")
####################################################

############# 2. ì±—ë´‡ í”„ë¡¬í”„íŠ¸, agent ì •ì˜ ############
# âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë‹¨ê³„ë³„ ìƒë‹´ + ê°€ì´ë“œë¼ì¸ ìœ ì§€)
system_prompt = load_prompt("chatbot_prompt.txt")


##### 3. chatbotê°ì²´(streamlit) ìƒì„± ë° ê¸°ëŠ¥ êµ¬í˜„ #####
# âœ… ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ (ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬)
if "chatbot" not in st.session_state:
    st.session_state["chatbot"] = Agent(system_prompt=system_prompt, api_key=openai_api_key)
# âœ… ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë²•ë¥  ìƒë‹´ì´ í•„ìš”í•˜ì‹œë©´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."}]

# âœ… ê¸°ì¡´ ëŒ€í™” UI ì¶œë ¥
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])


# âœ… ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    if not openai_api_key:
        st.info("ğŸ”‘ OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    time.sleep(1) # í˜¸ì¶œ ì „ 1ì´ˆ ëŒ€ê¸°

    client = OpenAI(api_key=openai_api_key)

    # ì‚¬ìš©ì ì…ë ¥ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    time.sleep(1) # 1ì´ˆ ëŒ€ê¸°
    # ì±—ë´‡ ì‘ë‹µ ìƒì„±
    chatbot_response = st.session_state["chatbot"](user_input)
    st.session_state.messages.append({"role": "assistant", "content": chatbot_response})
    st.chat_message("assistant").write(chatbot_response)
####################################################


############ 4. DB ê²€ìƒ‰ pdf_rag_chain ìƒì„± ###########

# PDF RAG í”„ë¡¬í”„íŠ¸ ë¡œë“œ
pdf_prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template=load_prompt("pdf_rag_prompt.txt")
)

# ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜
def format_docs(docs):
    return "\n\n---\n\n".join([doc.page_content + f"\nì¶œì²˜: {doc.metadata['source']}" for doc in docs])


# RAG ì²´ì¸ êµ¬ì„±
pdf_rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | pdf_prompt_template
    | llm
    | StrOutputParser()
)
####################################################


######## 5. Tavily ê²€ìƒ‰í•˜ëŠ” web_rag_chain ìƒì„± ########

# âœ… Tavily ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì •ë¦¬í•˜ì—¬ ë°˜í™˜"""
    formatted_docs = []
    for d in docs:
        text = f"Content: {d.page_content}"
        if hasattr(d, 'metadata') and 'source' in d.metadata:
            text += f"\nURL: {d.metadata['source']}"
        formatted_docs.append(text)
    return "\n\n---\n\n".join(formatted_docs)

# âœ… Tavily ê²€ìƒ‰ API í˜¸ì¶œ (ìºì‹± ì ìš©)
@st.cache_data(show_spinner=False)
def web_search(query):
    retriever = TavilySearchAPIRetriever(k=3, search_depth="advanced", include_domains=["news"], verbose=False)
    return retriever.invoke(query)

# âœ… Tavily ê²€ìƒ‰ ì„¤ì •
# Web RAG í”„ë¡¬í”„íŠ¸ ë¡œë“œ
web_prompt_template = ChatPromptTemplate.from_template(load_prompt("web_rag_prompt.txt"))

# âœ… Tavily ê²€ìƒ‰ RAG ì²´ì¸ (LLMì— ì˜¬ë°”ë¥¸ ì…ë ¥ íƒ€ì… ì „ë‹¬)
def web_rag_chain(query):
    """Tavily ê²€ìƒ‰ì„ ìˆ˜í–‰í•œ í›„ LLMì„ í†µí•´ ìµœì ì˜ ë‹µë³€ ìƒì„±"""
    search_results = web_search(query)  # ê²€ìƒ‰ ìˆ˜í–‰ (ìºì‹± ì ìš©)
    formatted_results = format_docs(search_results)  # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…

    # âœ… LLMì´ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ web_prompt_template.format() ì‚¬ìš©
    final_prompt = web_prompt_template.format(context=formatted_results, question=query)

    time.sleep(1) # 1ì´ˆ ëŒ€ê¸°
    return llm.invoke(final_prompt)  # âœ… str íƒ€ì…ìœ¼ë¡œ ë³€í™˜ëœ í”„ë¡¬í”„íŠ¸ ì „ë‹¬

####################################################

############ 6. ë””ë¹„, ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€ ###############

# âœ… ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "case_result" not in st.session_state:
    st.session_state["case_result"] = None  # ê´€ë ¨ ì‚¬ë¡€ ë° ì˜ˆìƒ ê²°ê³¼
if "law_result" not in st.session_state:
    st.session_state["law_result"] = None  # ê´€ë ¨ ë²•ë¥  ì •ë³´
if "loading" not in st.session_state:
    st.session_state["loading"] = False  # ìŠ¤í”¼ë„ˆ ìƒíƒœ


# ì‚¬ì´ë“œë°” - ê¸°ëŠ¥ ì†Œê°œ ë° ë²„íŠ¼ ì¶”ê°€
with st.sidebar:

    # ê²€ìƒ‰ ê¸°ëŠ¥ ì„¹ì…˜
    st.subheader("ğŸ” ê²€ìƒ‰ ë„êµ¬")
    st.caption("ğŸ’¬ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë²•ë¥  ê²€ìƒ‰ì´ ì§„í–‰ë©ë‹ˆë‹¤. ")
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“Š ê´€ë ¨ì‚¬ë¡€", use_container_width=True):
            st.session_state["loading"] = "case"
    
    with col2:
        if st.button("ğŸ“œ ë²•ë¥ ì •ë³´", use_container_width=True):
            st.session_state["loading"] = "law"
    
    # ë¡œê³  ë˜ëŠ” ì´ë¯¸ì§€ ì¶”ê°€ (ì„ íƒì‚¬í•­)
    st.markdown("---")
    
    # ê¸°ëŠ¥ ì†Œê°œ
    st.subheader("ğŸ“‹ ê¸°ëŠ¥ ì†Œê°œ")
    st.markdown("""
    ğŸ’¬ **ë²•ë¥  ìƒë‹´**: AI ë³€í˜¸ì‚¬ì™€ ë²•ë¥  ìƒë‹´í•˜ê¸° \n
    ğŸ” **ê´€ë ¨ì‚¬ë¡€ ê²€ìƒ‰**: ìœ ì‚¬ ì‚¬ë¡€ ë° ì˜ˆìƒ ê²°ê³¼ í™•ì¸ \n 
    ğŸ“š **ë²•ë¥ ì •ë³´ ê²€ìƒ‰**: ê´€ë ¨ ë²•ë¥  ì¡°í•­ ë° ì •ë³´ ì œê³µ
    """)
    
    st.markdown("---")
    
    # ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
    st.subheader("ğŸ’¬ ì±„íŒ… ê´€ë¦¬")
    if st.button("ğŸ”„ ì±„íŒ… ìƒˆë¡œí•˜ê¸°", use_container_width=True):
        # ì™„ì „íˆ ìƒˆë¡œìš´ ì±—ë´‡ ê°ì²´ ìƒì„± (ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ ì™„ì „ ì´ˆê¸°í™”)
        st.session_state["chatbot"] = Agent(system_prompt=system_prompt, api_key=openai_api_key)
        # í‘œì‹œë˜ëŠ” ë©”ì‹œì§€ ì´ˆê¸°í™”
        st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë²•ë¥  ìƒë‹´ì´ í•„ìš”í•˜ì‹œë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."}]
        
        # ê²€ìƒ‰ ê²°ê³¼ ì´ˆê¸°í™”
        st.session_state["case_result"] = None
        st.session_state["law_result"] = None
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()

    
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    st.caption("ê³ ê°ì„¼í„°: 02-1004-1004")
    st.caption("ì´ë©”ì¼: happy6team@skala.com")
    st.caption("ìš´ì˜ì‹œê°„: ì—°ì¤‘ë¬´íœ´ 24ì‹œê°„!")

if st.session_state["loading"]:
    with st.spinner("ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.ğŸ™"):
        summary = st.session_state["chatbot"].summarize_conversation()

        if summary.strip() == "ì§ˆë¬¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤." or summary.strip() == "ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.":   # Summaryê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
            st.warning("âš ï¸ ì•„ë¬´ëŸ° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € AIì™€ ëŒ€í™”ë¥¼ ì§„í–‰í•´ ì£¼ì„¸ìš”.")
            st.session_state["loading"] = False  # ë¡œë”© ìƒíƒœ ì´ˆê¸°í™”
        else:
            print(summary)
            if st.session_state["loading"] == "case":
                time.sleep(1) # 1ì´ˆ ëŒ€ê¸°
                st.session_state["case_result"] = web_rag_chain(f"{summary} ê´€ë ¨ëœ í˜•ëŸ‰ì´ë‚˜ ë²Œê¸ˆ ì •ë³´")

            if st.session_state["loading"] == "law":
                time.sleep(1) # 1ì´ˆ ëŒ€ê¸°
                st.session_state["law_result"] = pdf_rag_chain.invoke(f"{summary} ê´€ë ¨ëœ ë²•ë¥  ì •ë³´")

            st.session_state["loading"] = False  # ë¡œë”© ì™„ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™”

# âœ… ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
if st.session_state["case_result"]:
    st.subheader("ğŸ” ê²€ìƒ‰ëœ ê´€ë ¨ì‚¬ë¡€ ë° ì˜ˆìƒê²°ê³¼")
    st.write(st.session_state["case_result"].content)  # ì‚¬ë¡€ ì •ë³´ ìœ ì§€ë¨

if st.session_state["law_result"]:
    st.subheader("ğŸ“š ê²€ìƒ‰ëœ ë²•ë¥ ì •ë³´")
    st.write(st.session_state["law_result"])  # ë²•ë¥  ì •ë³´ ìœ ì§€ë¨
